{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP/SxH/1/QdAhEM8jdPKRo+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Deploying LLMs: Strategies and Considerations\n","\n","## Outline:\n","- Techniques for efficient deployment of LLMs in production environments.\n","- **Handds-on Lab:** Quantization, pruning, and distillation techniques.\n","\n","---\n","### Overview of Deployment Challenges\n","- High computational requirements\n","- Latency issues\n","- Scalability concerns\n","- Security and compliance\n","---\n","### Model Selection\n","- Choose an appropriate model (e.g., GPT-3, GPT-4, BERT) based on your needs\n","- Consider the trade-offs between model complexity and performance\n","\n","### Resource Allocation\n","- Estimate the computational resources required for training and inference\n","- Plan for infrastructure costs and scalability\n","---\n","## Optimization Techniques\n","- **Quantization:** Reduces model size and increases speed by lowering precision.\n","- **Pruning:** Removes unimportant connections to create a sparser, faster model.\n","- **Distillation:** Trains a smaller model to replicate a larger model's behavior, capturing its knowledge efficiently.\n","\n","\n","---\n","## Deployment Strategies\n","\n","### Batch Processing vs. Real-Time Inference\n","- **Batch Processing:** Suitable for non-time-sensitive tasks, efficient resource utilization\n","- **Real-Time Inference:** Essential for applications requiring immediate responses\n","---\n","\n"],"metadata":{"id":"9nnJrSvhcASQ"}},{"cell_type":"markdown","source":["## **Optimization Techniques for LLMs**\n","---\n","### Quantization\n","\n","\n","- Reducing the precision of model weights to decrease memory usage and increase inference speed\n","- Common techniques: 8-bit integer quantization, mixed precision training\n","- Types of Quantization\n","\n","  - **Post-Training Quantization:** Applied after training the model, converting weights from floating-point precision (e.g., FP32) to lower precision (e.g., INT8).\n","  - **Quantization-Aware Training:** The model is trained with quantization in mind, simulating low-precision calculations during training to better adjust the weights.\n","\n","- [TensorFlow Model Optimization Toolkit](https://www.tensorflow.org/model_optimization)\n","- [Post-Training Quantization](https://www.tensorflow.org/model_optimization/guide/quantization/post_training)\n","\n"],"metadata":{"id":"fYG6Irlwczsg"}},{"cell_type":"markdown","source":["### Pruning\n","\n","- Removing less important neurons or layers from the model to reduce its size and complexity and improve inference speed without significantly compromising accuracy.\n","- Methods: Magnitude pruning, structured pruning\n","- Types of Pruning\n","\n","  - **Magnitude-Based Pruning:** Removes weights with the smallest magnitudes.\n","  - **Structured Pruning:** Removes entire neurons, channels, or layers.\n","\n","\n","- [TensorFlow Model Optimization: Pruning](https://www.tensorflow.org/model_optimization/guide/pruning)\n","- [Neural Network Pruning: A Survey](https://arxiv.org/abs/1710.01878)\n","---"],"metadata":{"id":"KDiu15lVrl63"}},{"cell_type":"markdown","source":["### Knowledge Distillation\n","\n","- Training a smaller model (student) to replicate the performance of a larger pre-trained model (teacher)\n","- Benefits: Reduced computational requirements, faster inference\n","- The student model learns to mimic the teacher's output, effectively capturing the knowledge in a more compact form.\n","\n","- [Distilling the Knowledge in a Neural Network](https://arxiv.org/abs/1503.02531)\n","- [DistilBERT, a distilled version of BERT](https://arxiv.org/abs/1910.01108)\n","---"],"metadata":{"id":"5e1hpzyepWjy"}},{"cell_type":"markdown","source":["# **Lab:** Model Distillation\n","\n","- Perform knowledge distillation on a simple neural network for the MNIST dataset\n","- How small can be the Student model before you start seeing performance deterioration?\n","\n","\n"],"metadata":{"id":"y7HJazdCdbhc"}},{"cell_type":"code","source":[],"metadata":{"id":"trTkP33zs0Jn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ZImm3sYjs0Ps"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"0vkt4LvCs0V-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"KITETzMdxAmS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"-QCZ4N9zxArS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.quantization\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader\n","import copy\n"],"metadata":{"id":"zsJJH7IfxAxX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class SimpleNN(nn.Module):\n","    def __init__(self):\n","        super(SimpleNN, self).__init__()\n","        self.flatten = nn.Flatten()\n","        self.fc1 = nn.Linear(28*28, 512)\n","        self.relu = nn.ReLU()\n","        self.fc2 = nn.Linear(512, 10)\n","\n","    def forward(self, x):\n","        x = self.flatten(x)\n","        x = self.fc1(x)\n","        x = self.relu(x)\n","        x = self.fc2(x)\n","        return x\n","\n","model = SimpleNN()\n"],"metadata":{"id":"G7GHdn6lxBZo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n","\n","train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n","test_dataset = datasets.MNIST('./data', train=False, transform=transform)\n","\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n"],"metadata":{"id":"CXWvsVEnxDoY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train(model, device, train_loader, optimizer, criterion, epoch):\n","    model.train()\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = criterion(output, target)\n","        loss.backward()\n","        optimizer.step()\n","        if batch_idx % 100 == 0:\n","            print(f'Train Epoch: {epoch} [{batch_idx*len(data)}/{len(train_loader.dataset)} ({100.*batch_idx/len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = model.to(device)\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","criterion = nn.CrossEntropyLoss()\n","\n","for epoch in range(1, 6):\n","    train(model, device, train_loader, optimizer, criterion, epoch)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uNLFBJotxF3u","executionInfo":{"status":"ok","timestamp":1722565302827,"user_tz":240,"elapsed":113993,"user":{"displayName":"Vlad Skorokhod","userId":"12641846192617263153"}},"outputId":"280e0ece-95ef-4ade-844c-0db236f5b119"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.389661\n","Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.215629\n","Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.349619\n","Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.256759\n","Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.123129\n","Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.057196\n","Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.107390\n","Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.042111\n","Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.137711\n","Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.120072\n","Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.160205\n","Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.025055\n","Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.044451\n","Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.027020\n","Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.020329\n","Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.026232\n","Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.055556\n","Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.078579\n","Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.148932\n","Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.136036\n","Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.061359\n","Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.027800\n","Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.023883\n","Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.041318\n","Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.034294\n","Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.112223\n","Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.107873\n","Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.040727\n","Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.050531\n","Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.051158\n","Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.124715\n","Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.018709\n","Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.043112\n","Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.011381\n","Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.120323\n","Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.010870\n","Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.018489\n","Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.082962\n","Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.012019\n","Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.041706\n","Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.075850\n","Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.023315\n","Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.005565\n","Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.034527\n","Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.008870\n","Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.027893\n","Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.014113\n","Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.014234\n","Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.044887\n","Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.009518\n"]}]},{"cell_type":"code","source":["def test(model, device, test_loader):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            test_loss += criterion(output, target).item()\n","            pred = output.argmax(dim=1, keepdim=True)\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","    test_loss /= len(test_loader.dataset)\n","    accuracy = 100. * correct / len(test_loader.dataset)\n","    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} ({accuracy:.2f}%)\\n')\n","    return accuracy\n","\n","print(\"Original Model Performance:\")\n","original_accuracy = test(model, device, test_loader)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o-pr0FhzxIZD","executionInfo":{"status":"ok","timestamp":1722565306568,"user_tz":240,"elapsed":3754,"user":{"displayName":"Vlad Skorokhod","userId":"12641846192617263153"}},"outputId":"aba6d0e6-3973-435c-f20a-14c044fa00a2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Original Model Performance:\n","\n","Test set: Average loss: 0.0001, Accuracy: 9777/10000 (97.77%)\n","\n"]}]},{"cell_type":"code","source":["list(model.parameters())[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7KncOdYn5KcU","executionInfo":{"status":"ok","timestamp":1722565326817,"user_tz":240,"elapsed":198,"user":{"displayName":"Vlad Skorokhod","userId":"12641846192617263153"}},"outputId":"233cad20-64c0-45a9-c57e-cce62a33b711"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Parameter containing:\n","tensor([[-0.0058,  0.0423,  0.0571,  ...,  0.0131,  0.0508,  0.0180],\n","        [ 0.0229,  0.0404, -0.0243,  ..., -0.0061, -0.0089,  0.0215],\n","        [ 0.0150,  0.0047,  0.0189,  ...,  0.0017, -0.0199,  0.0299],\n","        ...,\n","        [ 0.0040, -0.0094, -0.0156,  ...,  0.0445,  0.0523,  0.0082],\n","        [ 0.0269,  0.0020,  0.0441,  ...,  0.0287,  0.0293,  0.0522],\n","        [ 0.0360,  0.0171,  0.0128,  ..., -0.0170,  0.0104,  0.0284]],\n","       requires_grad=True)"]},"metadata":{},"execution_count":55}]},{"cell_type":"code","source":["#distillation\n","\n","class SmallNN(nn.Module):\n","    def __init__(self):\n","        super(SmallNN, self).__init__()\n","        self.flatten = nn.Flatten()\n","        self.fc1 = nn.Linear(28*28, 128)\n","        self.relu = nn.ReLU()\n","        self.fc2 = nn.Linear(128, 10)\n","\n","    def forward(self, x):\n","        x = self.flatten(x)\n","        x = self.fc1(x)\n","        x = self.relu(x)\n","        x = self.fc2(x)\n","        return x\n","\n","student_model = SmallNN().to(device)\n","\n","def distillation_loss(student_outputs, teacher_outputs, labels, T, alpha):\n","    soft_targets = nn.functional.softmax(teacher_outputs / T, dim=1)\n","    student_loss = nn.functional.cross_entropy(student_outputs, labels)\n","    distillation_loss = nn.functional.kl_div(nn.functional.log_softmax(student_outputs / T, dim=1), soft_targets, reduction='batchmean') * (T * T)\n","    return alpha * student_loss + (1 - alpha) * distillation_loss\n","\n","teacher_model = model\n","teacher_model.eval()\n","student_optimizer = optim.Adam(student_model.parameters(), lr=0.001)\n","\n","for epoch in range(1, 6):\n","    student_model.train()\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        data, target = data.to(device), target.to(device)\n","        student_optimizer.zero_grad()\n","        student_output = student_model(data)\n","        teacher_output = teacher_model(data).detach()\n","        loss = distillation_loss(student_output, teacher_output, target, T=2.0, alpha=0.5)\n","        loss.backward()\n","        student_optimizer.step()\n","        if batch_idx % 100 == 0:\n","            print(f'Train Epoch: {epoch} [{batch_idx*len(data)}/{len(train_loader.dataset)} ({100.*batch_idx/len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')\n","\n","print(\"Distilled Student Model Performance:\")\n","distilled_accuracy = test(student_model, device, test_loader)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m0bCoLlzxfYu","executionInfo":{"status":"ok","timestamp":1722563614848,"user_tz":240,"elapsed":111545,"user":{"displayName":"Vlad Skorokhod","userId":"12641846192617263153"}},"outputId":"af33bb60-6985-4fb6-d2af-b915753fb04a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Train Epoch: 1 [0/60000 (0%)]\tLoss: 5.356724\n","Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.684561\n","Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.533737\n","Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.483549\n","Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.318062\n","Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.311646\n","Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.444755\n","Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.281863\n","Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.225640\n","Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.179527\n","Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.282141\n","Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.361051\n","Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.242415\n","Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.231823\n","Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.365924\n","Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.134131\n","Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.098530\n","Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.139512\n","Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.087308\n","Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.159450\n","Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.193451\n","Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.097274\n","Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.100871\n","Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.049357\n","Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.143197\n","Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.191472\n","Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.083786\n","Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.117686\n","Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.115396\n","Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.086937\n","Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.073822\n","Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.103710\n","Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.028512\n","Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.057374\n","Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.064521\n","Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.102014\n","Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.079113\n","Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.051720\n","Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.213174\n","Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.043341\n","Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.053425\n","Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.041254\n","Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.089137\n","Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.107292\n","Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.051262\n","Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.038382\n","Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.149810\n","Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.057181\n","Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.137127\n","Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.055101\n","Distilled Student Model Performance:\n","\n","Test set: Average loss: 0.0001, Accuracy: 9754/10000 (97.54%)\n","\n"]}]},{"cell_type":"code","source":["list(teacher_model.parameters())[0].shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"adLLIwIx2VpJ","executionInfo":{"status":"ok","timestamp":1722565065240,"user_tz":240,"elapsed":204,"user":{"displayName":"Vlad Skorokhod","userId":"12641846192617263153"}},"outputId":"e9e6875a-71f9-480b-cbe7-f7459ce41f36"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([512, 784])"]},"metadata":{},"execution_count":46}]},{"cell_type":"code","source":["list(student_model.parameters())[0].shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dYjJtCeo4GXT","executionInfo":{"status":"ok","timestamp":1722565081927,"user_tz":240,"elapsed":200,"user":{"displayName":"Vlad Skorokhod","userId":"12641846192617263153"}},"outputId":"242f7d1f-c40d-4fd8-fa14-26a9ff4440c6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([128, 784])"]},"metadata":{},"execution_count":47}]},{"cell_type":"code","source":["list(teacher_model.parameters())[1].shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u8B8YcmI4Tlr","executionInfo":{"status":"ok","timestamp":1722565095198,"user_tz":240,"elapsed":213,"user":{"displayName":"Vlad Skorokhod","userId":"12641846192617263153"}},"outputId":"2f2f2ed6-e55c-45cc-88e7-e60df75bc592"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([512])"]},"metadata":{},"execution_count":48}]},{"cell_type":"code","source":["list(student_model.parameters())[1].shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IkAbXfNA4W1m","executionInfo":{"status":"ok","timestamp":1722565114075,"user_tz":240,"elapsed":172,"user":{"displayName":"Vlad Skorokhod","userId":"12641846192617263153"}},"outputId":"c7d4c12c-72c8-437b-8987-db26e3c87dbb"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([128])"]},"metadata":{},"execution_count":49}]},{"cell_type":"code","source":[],"metadata":{"id":"xhXSwksm4bdW"},"execution_count":null,"outputs":[]}]}