{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T1ml2Iv4Ecff"
   },
   "source": [
    "# **Foundations of AI and Machine Learning**\n",
    "\n",
    "## Outline\n",
    "- Machine Learning vs Instruction-based programming.\n",
    "- Supervised and unsupervised learning paradigms. Examples and applications in real-world scenarios.\n",
    "- Basics of model training, evaluation metrics, and performance assessment techniques.\n",
    "- **Hands-on Lab:** Training a classifier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Imdb_BmEcfi"
   },
   "source": [
    "## **Understanding Artificial Intelligence**\n",
    "\n",
    "<img src=\"./images/artificial-intelligence.webp\" width=\"700\" align=\"center\"/>\n",
    "\n",
    "- It explores the possibility of endowing computers with intelligent behaviors, akin to those exhibited by humans.\n",
    "\n",
    "- Today's computers, while vastly more advanced than Babbage's designs, still adhere to the fundamental concept of controlled computations.\n",
    "  - They operate based on algorithms, following precise sequences of instructions to perform tasks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UHcoy1s8Ecfi"
   },
   "source": [
    "## **Programming for Intelligence**\n",
    "\n",
    "- Programming a computer to accomplish a task is feasible\n",
    "  - **if** we understand the necessary sequence of steps\n",
    "- Algorithms play a pivotal role in directing computers to achieve specific goals.\n",
    "\n",
    "- Modern computing relies on the idea of **controlled computations**\n",
    "  - Computers execute tasks methodically, relying on algorithms to guide their actions.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sq7jgfgJEcfj"
   },
   "source": [
    "## **Weak AI vs. Strong AI**\n",
    "\n",
    "<img src=\"./images/WAIS.png\" width=\"500\" align=\"center\"/>\n",
    "\n",
    "#### **Weak AI**\n",
    "\n",
    "- Weak AI refers to systems designed to solve **specific**, **narrowly-defined** tasks.\n",
    "  - Identifying a person's age from a photo.\n",
    "- These systems do not possess **general intelligence** or the ability to perform a wide range of tasks like a human being.\n",
    "  - Lacks the cognitive abilities associated with human intelligence.\n",
    "- Any Weak AI example in your environment?\n",
    "\n",
    "#### **Strong AI (Artificial General Intelligence - AGI)**\n",
    "\n",
    "- Also known as Artificial General Intelligence (AGI),\n",
    "  - Aims to create a system with human-like intelligence\n",
    "- It seeks to develop computers that can perform a broad spectrum of tasks, similar to **human cognitive** capabilities\n",
    "- Achieving Strong AI is a complex and ambitious goal\n",
    "  - As it involves replicating human-level intelligence and understanding\n",
    "\n",
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xunhzOj0Ecfk"
   },
   "source": [
    "## **The Turing Test**\n",
    "\n",
    "<img src=\"./images/what-is-the-turing-test.jpg\" width= 400 align=\"center\"/>\n",
    "\n",
    "####  Alan Turing's Turing Test\n",
    "\n",
    "- Alan Turing proposed the Turing Test as a means to assess the intelligence of a computer system.\n",
    "- The test compares the system's responses to those of a human being in a text-based dialogue.\n",
    "- The goal is for the system to mimic human-like responses to the extent that a human interrogator cannot reliably distinguish between the two.\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JBjXcJu9Ecfk"
   },
   "source": [
    "## **Understanding Human Intelligence for AI**\n",
    "\n",
    "\n",
    "- To make a computer behave like a human, we must model our way of thinking.\n",
    "- Understanding human intelligence is essential for programming it into a machine.\n",
    "- Human decision-making involves subconscious and reasoning processes.\n",
    "\n",
    "#### **Two Approaches to AI**\n",
    "\n",
    "##### 1. Top-down Approach (Symbolic Reasoning)\n",
    "\n",
    "- **Characteristics:**\n",
    "  - Models human reasoning.\n",
    "  - Involves extracting and representing human knowledge in a computer-readable form.\n",
    "  - Requires modeling reasoning processes inside a computer.\n",
    "- **Example**\n",
    "  - Automated traffic signal control systems\n",
    "    - Predefined rules and logic dictate when to change traffic lights based on traffic flow and patterns\n",
    "\n",
    "<img src=\"./images/traffic.jpeg\" width= 500 align=\"center\"/>\n",
    "\n",
    "#####  2. Bottom-up Approach (Neural Networks)\n",
    "\n",
    "- **Characteristics:**\n",
    "  - Models the structure of the human brain.\n",
    "  - Utilizes neurons as simple units that perform weighted averaging of inputs.\n",
    "  - Training neural networks with data enables them to solve practical problems.\n",
    "- **Example**\n",
    "  - Image recognition\n",
    "      - Starts with individual pixels\n",
    "      - Gradually builds complex features and patterns\n",
    "        - Identify objects without explicit programming\n",
    "\n",
    "<img src=\"./images/imagerecog.jpg\" width= 500 align=\"center\"/>\n",
    "\n",
    "#### Other Approaches\n",
    "\n",
    "- **Emergent, Synergetic, or Multi-agent Approach:**\n",
    "  - Complex intelligent behavior arises from interactions among numerous simple agents.\n",
    "  - Intelligence emerges from reactive behavior during metasystem transition.\n",
    "\n",
    "- **Evolutionary Approach (Genetic Algorithm):**\n",
    "  - Utilizes optimization principles based on the concept of evolution.\n",
    "  - Mimics natural selection to optimize solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vloE0JN9Ecfl"
   },
   "source": [
    "## **The Top-Down Approach: Symbolic Reasoning**\n",
    "\n",
    "#### Modeling Human Reasoning\n",
    "\n",
    "- In the top-down approach, we aim to model **human reasoning**\n",
    "- We formalize the **thought processes** that guide human decision-making.\n",
    "- This approach is known as **symbolic reasoning**.\n",
    "- Example: Recipe Recommendation\n",
    "  - How a human chef thinks when creating recipes\n",
    "  -  \"spicy + meat = Mexican cuisine\"\n",
    "\n",
    "#### Rule-Based Decision Making\n",
    "\n",
    "- Human decision makers often follow **internal rules** when solving problems\n",
    "  - A doctor diagnosing a patient may use rules to connect symptoms and potential causes\n",
    "- By applying a set of rules to a specific problem\n",
    "\n",
    "#### Knowledge Representation and Reasoning\n",
    "\n",
    "- Central to the top-down approach is **knowledge representation** and **reasoning**.\n",
    "- Extracting knowledge from human experts can be **challenging**\n",
    "  - Experts sometimes arrive at conclusions without explicit reasoning.\n",
    "\n",
    "#### Challenges in Knowledge-Based Tasks\n",
    "\n",
    "- Some tasks, like determining a person's age from a photograph, **cannot** be reduced solely to knowledge manipulation\n",
    "- Complex, nuanced tasks (e.g., diplomatic negotiations) may not align well with symbolic reasoning\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/wsko/hands-on-gen-ai-2/main/images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>\n",
    "\n",
    "## **The Bottom-Up Approach: Artificial Neural Networks**\n",
    "\n",
    "#### Modeling Neurons\n",
    "\n",
    "- Alternatively, we can model the basic elements of the human brain: neurons.\n",
    "- Artificial neural networks emulate the structure and function of neurons.\n",
    "\n",
    "#### Learning by Example\n",
    "\n",
    "- Like a newborn learning by observation, we teach artificial neural networks through examples.\n",
    "- By providing training data, the network learns to solve problems by adjusting its internal connections.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aMsmwAaWEcfn"
   },
   "source": [
    "## Discussion\n",
    "\n",
    "- Identify where AI is most effectively utilized.\n",
    "- AI applications are prevalent across various domains, enhancing user experiences and enabling new functionalities.\n",
    "  - Mapping Applications\n",
    "  - Speech-to-Text Services\n",
    "  - Video Games\n",
    "\n",
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2FOkclKJEcfo"
   },
   "source": [
    "## **Machine Learning and Neural Networks**\n",
    "\n",
    "\n",
    "<img src=\"./images/ML.png\" width=\"500\" align=\"center\"/>\n",
    "\n",
    "\n",
    "- Machine Learning is a field within Artificial Intelligence focused on **training computer models** using **data** to **solve problems**\n",
    "\n",
    "- In Machine Learning, we work with datasets consisting of input examples (X) and corresponding output values (Y)\n",
    "  - Examples are typically represented as N-dimensional vectors with features.\n",
    "  - Outputs are referred to as labels.\n",
    "\n",
    "## **Common Machine Learning Problems**\n",
    "\n",
    "- Two fundamental Machine Learning problems are:\n",
    "  - **Classification:** Assigning input objects into two or more predefined classes or categories.\n",
    "    - Medical diagnostics\n",
    "  - **Regression:** Predicting numerical values for each input sample.\n",
    "    - Housing prices\n",
    "\n",
    "<img src=\"./images/house.png\" width=\"500\" align=\"center\"/>\n",
    "\n",
    "## **Tensor Representation**\n",
    "\n",
    "<img src=\"./images/tensors.jpeg\" width=\"500\" align=\"center\"/>\n",
    "\n",
    "- In Machine Learning, data is often represented as tensors.\n",
    "- The input dataset is a matrix of size M×N, where M is the number of samples and N is the number of features.\n",
    "- Output labels (Y) are a vector of size M.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "caf3dc8a"
   },
   "source": [
    "### Machine Learning definition\n",
    "\n",
    "\n",
    "__“The field of study that gives computers the ability to learn without being explicitly programmed\" (Arthur Samuel, 1959)__\n",
    "\n",
    "\n",
    "__Example: Self-driving cars__\n",
    "- Rule-based: Tell the car the rules for all possible scenarios\n",
    "- Machine Learning: Let the car record the scenery and your reactions, then let it predict the next reaction\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "39b83180"
   },
   "source": [
    "### Rule-based systems: examples and limitation\n",
    "\n",
    "- Credit card fraud detection https://fraud.net/d/rules-based-fraud-detection/\n",
    "- Loan application approval  https://www.researchgate.net/publication/220841474_Presenting_a_Rule_Based_Loan_Evaluation_Expert_System\n",
    "- __Problem:__ too many rules.\n",
    "Works only for specific domains with limited, clear rules, e.g. chess\n",
    "\n",
    "### Learning from examples without explicit programming\n",
    "- Self-driving vehicles\n",
    "- Image classification https://www.kaggle.com/competitions/dogs-vs-cats\n",
    "- Language translation\n",
    "    \n",
    "### Resources\n",
    "\n",
    "- __Book__\n",
    "    - https://hastie.su.domains/Papers/ESLII.pdf\n",
    "\n",
    "\n",
    "- __Communities__\n",
    "    - https://www.kdnuggets.com/\n",
    "    - https://www.kaggle.com/\n",
    "\n",
    "\n",
    "- __Key Influencers__\n",
    "    - Andrew Ng\n",
    "    - Yann LeCun\n",
    "\n",
    "### Sci-kit learn\n",
    "- https://scikit-learn.org/stable/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SJYqQfOvvSRP"
   },
   "source": [
    "### What Are Some Common Questions Asked in Data Science?\n",
    "\n",
    "**Machine learning more or less asks the following questions:**\n",
    "\n",
    "- Does X predict Y?\n",
    "- Are there any distinct groups in our data?\n",
    "- What are the key components of our data?\n",
    "- Is one of our observations “weird”?\n",
    "\n",
    "**From a business perspective, Data Science can help us with use cases such as:**\n",
    "\n",
    "- What is the likelihood that a customer will buy this product?\n",
    "- Is this a good or bad review?\n",
    "- How much demand will there be for my service tomorrow?\n",
    "- Is this the cheapest way to deliver my goods?\n",
    "- Is there a better way to segment my marketing strategies?\n",
    "- What groups of products are customers purchasing together?\n",
    "- Can we automate this simple yes/no decision?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KI-kiBfGvSRP"
   },
   "source": [
    "## Are AI and Machine Learning different things?\n",
    "\n",
    "The AI onion\n",
    "\n",
    "- Artificial intelligence is an umbrella term that covers machine learning and deep learning\n",
    "- Deep learning and neural networks are also types of machine learning algorithms  \n",
    "- What Data Science VS. (Machine Learning Engineer):\n",
    "\n",
    "\n",
    "<img src=\"./images/onion.png?raw=1\" width=\"270\" height=\"270\" align=\"center\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rOBUPOlfvSRQ"
   },
   "source": [
    "## AI History\n",
    "\n",
    "<img src=\"./images/aiml.png?raw=1\" width=\"800\" align=\"center\"/>\n",
    "\n",
    "\n",
    "<img src=\".s/images/aiwinters.png?raw=1\" width=\"800\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RxoRzl7KvSRQ"
   },
   "source": [
    "## Why now?\n",
    "\n",
    "---\n",
    "\n",
    "In the last few years there has been a lot of advancements in technologies that enable AI\n",
    "> - Compute Power\n",
    "> - Big Data\n",
    "> - Powerful Algorithms\n",
    "\n",
    "<img src=\"./images/whynow.png?raw=1\" width=\"500\" align=\"center\"/>\n",
    "\n",
    "Read more here: https://www.mckinsey.com/business-functions/mckinsey-analytics/our-insights/an-executives-guide-to-ai\n",
    "\n",
    "Can you mention examples of advancements in the above technologies?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RvpTNXIPvSRQ"
   },
   "source": [
    "# Data collected every minute\n",
    "<img src=\"./images/data.png?raw=1\" width=\"400\" height=\"400\" align=\"center\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7tnGJrx6vSRQ"
   },
   "source": [
    "## Why is AI powerful?\n",
    "<img src=\"./images/ny-vs-sf.jpg\" height=\"350\" align=\"center\"/>\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"./images/nysf.png\"  height=\"350\" align=\"center\"/>\n",
    "\n",
    "\n",
    "Check the demo here:\n",
    "http://www.r2d3.us/visual-intro-to-machine-learning-part-1/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KS5XmZabvSRR"
   },
   "source": [
    "<a id=\"dswf\"></a>\n",
    "## Introduction: The Data Science Workflow\n",
    "\n",
    "---\n",
    "- **Understand the Business Problem**: Develop a hypothesis-driven approach to your analysis.\n",
    "- **Data Acquisition and Understanding**: Select, import, explore, and clean your data.\n",
    "- **Build a Model**: engineer your data, build models, evaluate them and build the best model.\n",
    "- **Deployment**: deploy your model in production and deliver ROI!\n",
    "\n",
    "<img src=\"./images/lifecycle.png\" height=\"650\" align=\"center\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dR9SnHFqvSRR"
   },
   "source": [
    "# This is what data scientists do\n",
    "\n",
    "Data scientists identify relevant questions, collect data from a multitude of different data sources, organize the information, translate results into solutions, and communicate their findings in a way that positively affects business decisions. These skills are required in almost all industries, causing skilled data scientists to be increasingly valuable to companies.\n",
    "\n",
    "<img src=\"./images/timewise.png\" height=\"400\" align=\"center\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UFc3h8H4vSRR"
   },
   "source": [
    "\n",
    "### Data scientist vs. machine learning engineer\n",
    "While there’s some overlap, which is why some data scientists with software engineering backgrounds move into machine learning engineer roles, data scientists focus on analyzing data, providing business insights, and prototyping models, while machine learning engineers focus on coding and deploying complex, large-scale machine learning products."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g0z09U6ovSRR"
   },
   "source": [
    "## What data engineers, analysts and architects do?\n",
    "\n",
    "ETL and Data Cleaning are the most time consuming steps\n",
    "\n",
    "> Data scientists work with machine learning engineers to move their models to production\n",
    "\n",
    "<img src=\"./images/time.jpg\" width=\"900\" align=\"center\"/>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "up0ym2gmvSRS"
   },
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>\n",
    "\n",
    "# Data Science Lifecycle Step by Step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Sa3CFi1vSRS"
   },
   "source": [
    "# Step 1. Business Understanding\n",
    "\n",
    "---\n",
    "\n",
    "- Identify the business/product objectives.\n",
    "- Identify and hypothesize goals and criteria for success.\n",
    "- Create a set of questions to help you identify the correct data set.\n",
    "\n",
    "## An Example Use Case\n",
    "We work for a real estate company interested in using data science to determine the best properties to buy and resell. Specifically, your company would like to identify the characteristics of residential houses that estimate their sale price and the cost-effectiveness of doing renovations.\n",
    "\n",
    "> #### Identify the Business/Product Objectives\n",
    "\n",
    "The customer tells us their business goals are to accurately predict prices for houses (so that they can sell them for as large a profit as possible) and to identify which kinds of features in the housing market would be more likely to lead to foreclosure and other abnormal sales (which could represent more profitable sales for the company).\n",
    "\n",
    "> #### Identify and Hypothesize Goals and Criteria for Success\n",
    "\n",
    "Ultimately, the customer wants us to:\n",
    "* Deliver a presentation to the real estate team.\n",
    "* Write a business report discussing results, procedures used, and rationales.\n",
    "* Build an API that provides estimated returns.\n",
    "\n",
    "> #### Create a Set of Questions to Help You Identify the Correct Data Set\n",
    "\n",
    "* Can you think of questions that would help this customer deliver on their business goals?\n",
    "* What sort of features or columns would you want to see in the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RBHvWo_hvSRS"
   },
   "source": [
    "# Step 2. Data Acquisition\n",
    "\n",
    "** Ideal Data vs. Available Data**  \n",
    "\n",
    "Oftentimes, we'll start by identifying the *ideal data* we would want for a project.\n",
    "\n",
    "Then, during the data acquisition phase, we'll learn about the limitations on the types of data actually available. We have to decide if these limitations will inhibit our ability to answer our question of interest or if we can work with what we have to find a reasonable and reliable answer.\n",
    "\n",
    "For example, we provide a set of housing data for Ames, Iowa, which [includes](./extra-materials/ames_data_documentation.txt):\n",
    "\n",
    "- 20 continuous variables indicating square footage.\n",
    "- 14 discrete variables indicating number of each room type.\n",
    "- 46 categorical variables containing 2–28 classes each, e.g., street type (gravel/paved) and neighborhood (city district name).\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T5fT32OdvSRS"
   },
   "source": [
    "\n",
    "### **Review the Dataset**\n",
    "\n",
    "Take a moment to look through the data description. How closely does the set match the ideal data that you envisioned? Would it be sufficient for our purposes? What limitations does it have?\n",
    "\n",
    "---\n",
    "\n",
    "This is possibly the hardest step in the data science workflow. At this stage, it's common to realize that the problem you're trying to solve may not be solvable with the information available. The data could be incomplete, non-existant, or unable to meet the criteria necessary to answer your question.  \n",
    "\n",
    "That said, you now have a better feel for the data that's available and the information they could contain. You can now identify a new, answerable question that ultimately helps you solve or better understand your problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nTbPT-GJvSRS"
   },
   "source": [
    "## 2.1 Data Wrangling & Cleaning\n",
    "\n",
    "This is by far the most time consuming step of Data Science Lifecyle\n",
    "\n",
    "For the Ames housing dataset we discussed,\n",
    "- What if the data are in different databases and we have to consolidate them?\n",
    "- What if the values for some columns in the dataset are missing or in wrong format?\n",
    "\n",
    "\n",
    "<img src=\"./images/datac.png\" width=\"400\" height=\"400\" align=\"center\"/>\n",
    "\n",
    "\n",
    "** we will review and practice the data cleaning process as part of this course. **\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y2OtbKF5vSRT"
   },
   "source": [
    "# Step 3. Modeling\n",
    "** What is a Model? **\n",
    "\n",
    "- Using Machine Learning algorithms we build a model from input data (image, text, ...)\n",
    "> - In case of housing data set discussed above we can build a model that learns how to predict price of a house\n",
    "- The resulted model is a representative of the data used for training\n",
    "\n",
    "<img src=\"./images/model.png\"  height=\"400\" align=\"center\"/>\n",
    "\n",
    "> - The size of the output model can be alot smaller than the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ue7NueXTvSRT"
   },
   "source": [
    "## There are many algorithms that can be used to build a model\n",
    "\n",
    "<img src=\"./images/modelS.png\" height=\"500\" align=\"center\"/>\n",
    "\n",
    "> - Depending on the use case, requirements and available data, a model will be selected!\n",
    "\n",
    "## Data scientists use one of these available algorithms and tune it for their use case\n",
    "> - Most these algorithms are available in public and open source libraries\n",
    "\n",
    "> - Most data Scientists do no build their own algorithms, they just customize and tune an existing algorithm  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GrDuqDIOvSRT"
   },
   "source": [
    "<a id=\"common-ml-defs\"> </a>\n",
    "## 3.1 Supervised  vs. Unsupervised Learning\n",
    "\n",
    "There are two main categories of machine learning: supervised learning and unsupervised learning.\n",
    "\n",
    "**Supervised learning (a.k.a., “predictive modeling”):**  \n",
    "_Classification and regression_\n",
    "- Predicts an outcome based on input data.\n",
    "    - Example: Predicts whether an email is spam or ham.\n",
    "- Attempts to generalize.\n",
    "- Requires past data on the element we want to predict (the target).\n",
    "\n",
    "**Unsupervised learning:**  \n",
    "_Clustering and dimensionality reduction_\n",
    "- Extracts structure from data.\n",
    "    - Example: Segmenting grocery store shoppers into “clusters” that exhibit similar behaviors.\n",
    "- Attempts to represent.\n",
    "- **Does not require** past data on the element we want to predict.\n",
    "\n",
    "<img src=\"https://github.com/wsko/machinie-learning-fundamentals-ps/blob/main/AI%20and%20ML%20Concepts/images/sup.png?raw=1\" width=\"800\" align=\"center\"/>\n",
    "\n",
    "\n",
    "Oftentimes, we may combine both types of machine learning in a project to reduce the cost of data collection by learning a better representation. This is referred to as transfer learning.\n",
    "\n",
    "Unsupervised learning tends to present more difficult problems because its goals are amorphous. Supervised learning has goals that are almost too clear and can lead people into the trap of optimizing metrics without considering business value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4nvhRwIVvSRT"
   },
   "source": [
    "## 3.2 Feature Engineering\n",
    "\n",
    "#### Data Enrichment\n",
    "\n",
    "- Machine learning algorithms need the data to be engineered before they consume it\n",
    "\n",
    "\n",
    "<img src=\"./images/garbage.png\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "> - We need feature engineering to enrich the raw data\n",
    "\n",
    "\n",
    "> - Brainstorm features.\n",
    "> - Create features.\n",
    "> - Check how the features work with the model.\n",
    "> - Start again from first until the features work perfectly.\n",
    "\n",
    "\n",
    "So here is another definition of feature engineering:\n",
    "\n",
    "### Feature engineering is the process of transforming raw data into features that better represent the underlying problem to the predictive models, resulting in improved model accuracy on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LKdSmpA9vSRT"
   },
   "source": [
    "## 3.3 OverFitting and UnderFitting\n",
    "\n",
    "\n",
    "What is a Good Model?\n",
    "Arguably, Machine Learning models have one sole purpose; to generalize well.\n",
    "\n",
    "> Generalization is the model’s ability to give sensible outputs to sets of input that it has never seen before.\n",
    "\n",
    "### Example: which model (red) has the best ability to generalize the training data (blue)?\n",
    "\n",
    "<img src=\"./images/under-over-fit.png\" width=\"900\" align=\"center\"/>\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D6Pl0wktvSRU"
   },
   "source": [
    "## 3.4 Test Train Split\n",
    "\n",
    "Should we use all the data for training a model?\n",
    "\n",
    "\n",
    "> Data Scientists usually keep parts of the data for testing the model performance\n",
    "<img src=\"./images/ttsplit.jpg?raw=1\" width=\"500\" align=\"center\"/>\n",
    "\n",
    "> if we use all the data for training then we do not have any way of evaluating the model performance.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9GSFHQ2zvSRU"
   },
   "source": [
    "### Cross Validation\n",
    "\n",
    "> why to have a fixed test and train split when we can use different combination of test and train data?\n",
    "\n",
    "<img src=\"./images/cross.png\" width=\"350\" align=\"center\"/>\n",
    "\n",
    "Instead of using one fixed set of the data for test and train we can use cross validation.\n",
    "> - In Cross Validation we use different parts of the data for test and training purposes to evaluate the model performance\n",
    "\n",
    "> - Then average performance of different test and train splits can be used as final performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d_oeqbdpvSRU"
   },
   "source": [
    "# Step 4. Use Cases\n",
    "**What are some of the use cases for AI/ML?**\n",
    "\n",
    "- Nearly all occupations will be affected by automation, but only about 5 percent of occupations could be fully automated by currently demonstrated technologies.\n",
    "- Many more occupations have portions of their constituent activities that are automatable:we find that about 30 percent of the activities in 60 percent of all occupations could be automated.\n",
    "\n",
    "<img src=\"./images/usecase.svg?raw=1\" width=\"800\" align=\"center\"/>\n",
    "\n",
    "> - the size of the output model can be alot smaller than the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ITlQdjzvSRU"
   },
   "source": [
    "## 4.1  Example AI Use Cases\n",
    "\n",
    "> **Instructor Note**: This is a good section in which to provide your own work (or side project) experience as well! These are just a couple of options:\n",
    "- [This Person is not real](https://thispersondoesnotexist.com/)\n",
    "- [Google Quick Draw](https://quickdraw.withgoogle.com/)\n",
    "- [Deep Dream Generator](https://deepdreamgenerator.com/)\n",
    "- Add your own!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G4R1JEaIvSRV"
   },
   "source": [
    "## AI Ethics\n",
    "\n",
    "\n",
    "### Data-Biasing\n",
    "\n",
    "The quality of your model is usually a direct result of the quality and quantity of your data.\n",
    "\n",
    "You can imagine a myriad of situations in which classification problems could go wrong because of bias in past data. From an ethical perspective, I think we can all agree that systems which discriminate against individuals on the basis of race, gender, age, ethnicity, etc.\n",
    "\n",
    "Some bad outcomes:\n",
    "> Security systems trained to discriminate based on an individual’s race or gender.\n",
    "\n",
    "> An AI based resume review tool that values the gender of applicants\n",
    "\n",
    "> Facial recognition systems that lack a diverse training set, resulting in only detecting the race for which they are trained\n",
    "\n",
    "> Court systems (AI judges/juries) with past biased rulings against certain races as the training data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c41432ff"
   },
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>\n",
    "\n",
    "\n",
    "# Machine Learning Algorithms\n",
    "\n",
    "\n",
    "### Linear Regression\n",
    "\n",
    "- Supervised learning algorithm\n",
    "\n",
    "- Maps Label _y_ to Features _X_ using a linear expression: $y = c_0 + c_1 x_1 + c_2 x_2 + ... +c_N x_N$\n",
    "\n",
    "- Label _y_ is continuous numerical\n",
    "\n",
    "- Training a linear regression model means computing its coefficients to minimize model error (optimization problem)\n",
    "\n",
    "- Parametric model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "90f7df7e"
   },
   "source": [
    "## Example: Tips Data\n",
    "\n",
    "- Can we predict the amount of a tip from the total amount of the restaurant bill?\n",
    "#### Univariate linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9e40cf8e"
   },
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eb0689c7"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c55077f7"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/tips.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "e10e7377",
    "outputId": "3c0eb470-902d-483d-e423-a2ef0b0a02c7"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6e3e91ee",
    "outputId": "8533aa88-cce8-4260-a3b9-47685a39859a"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "17817171",
    "outputId": "811caa7e-0267-41af-fe30-c30d4a7735b9"
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4bbd7d90"
   },
   "source": [
    "### Create Feature and Label arrays\n",
    "\n",
    "- Note that `sklearn` requires data in a form of a numerical (NumPy) arrays:\n",
    "    - Label array (1d)\n",
    "    - Features array (2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bea33acd"
   },
   "outputs": [],
   "source": [
    "X = df[[\"total_bill\"]].to_numpy()  ## feature\n",
    "y = df['tip'].to_numpy()  ## label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9XVOxsNvVL7y"
   },
   "outputs": [],
   "source": [
    "# X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d382ec2c"
   },
   "source": [
    "### Train a Linear Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "42d10d10"
   },
   "outputs": [],
   "source": [
    "### instantiate a blank linear regression model as a Python object\n",
    "\n",
    "lrm = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "ef67a780",
    "outputId": "0572c7be-1ee6-44d0-813f-cd146c8cb928"
   },
   "outputs": [],
   "source": [
    "### use .fit() method to train the model on X and y. Note that .fit() is executed in-place\n",
    "\n",
    "lrm.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "03a459ec",
    "outputId": "3d0aebc3-12f8-4293-b71d-c68060f49ae8"
   },
   "outputs": [],
   "source": [
    "## display model parameters. What story do they tell?\n",
    "pd.Series([lrm.coef_[0], lrm.intercept_], index = ['slope', 'intercept'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-Uy47QTlWff7",
    "outputId": "2fdb28c0-eeab-441a-f597-fa695213b282"
   },
   "outputs": [],
   "source": [
    "## predict Tip from new values of Total Bill\n",
    "\n",
    "lrm.predict(np.array([[0],[ 100]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fc6a0b57"
   },
   "source": [
    "#### Model Interpretation\n",
    "\n",
    "- What is the meaning of slope and intercept?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "c626ef2f",
    "outputId": "b2397a51-6530-4d6e-c6b5-c877ddce9fca",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## how well does our model predict Tip? What causes prediction errors?\n",
    "df['tip_predicted'] = lrm.predict(X)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "id": "1b978725",
    "outputId": "f2d09c62-8e96-47a6-d35f-190ff0167792"
   },
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(data = df, x = 'total_bill', y = 'tip', label = 'data')\n",
    "ax = sns.scatterplot(data = df, x = 'total_bill', y = 'tip_predicted', label = 'model')\n",
    "ax.legend()\n",
    "ax.set_xlim(0, 55)\n",
    "ax.set_ylim(0, 11)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a2d4ecb1"
   },
   "source": [
    "### Model Scoring\n",
    "\n",
    "- How good is our predictive model? How do we measure prediction errors?\n",
    "- Compare known and predicted values of the label `y` vs `y_pred`\n",
    "\n",
    "#### Mean Squared Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VktoqXOjHLyh"
   },
   "source": [
    "    \n",
    "<img src=\"./images/linear_regression.png\" width=\"400\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5a1d1ee8",
    "outputId": "e355cd34-e124-47ca-e503-f25e9a4f8e59"
   },
   "outputs": [],
   "source": [
    "mean_squared_error(y, lrm.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "37702eae"
   },
   "source": [
    "- MSE is a mean squared difference between the known and predicted values of `y`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d3bfa378"
   },
   "source": [
    "## Multivariate Linear Regression\n",
    "\n",
    "- Linear regression requires all features to be numerical\n",
    "- To convert categorical data into numerical, use one hot encoding (`pd.get_dummies()`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "3d6940fc",
    "outputId": "1b4b1323-104f-40cf-d6d0-1893cecaeced",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/tips.csv\")\n",
    "## feature engineering: transform categforiucal data into numerical using one-hot encoding\n",
    "df_feature_engineered = pd.get_dummies(df, drop_first=True).astype('float')\n",
    "df_feature_engineered.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "320bebfd"
   },
   "source": [
    "- Next, let's build numerical arrays X and y and train a LR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0ee57e2b",
    "outputId": "9b622f9d-5cc4-482b-fa9d-377c11bc3b4e",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "label = 'tip'\n",
    "features = list(df_feature_engineered.columns)\n",
    "features.remove(label)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9ba9022e"
   },
   "outputs": [],
   "source": [
    "X = df_feature_engineered[features].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AcdC8el2bgPB",
    "outputId": "ec407218-1582-408e-c82b-ee74aded0869"
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "25ee01bb",
    "outputId": "605f3bee-446e-44ec-9845-af8b54181c53"
   },
   "outputs": [],
   "source": [
    "lrm = LinearRegression()\n",
    "lrm.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "48e3e0c5"
   },
   "source": [
    "- Model slopes: now we have one coefficient per each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9f080127",
    "outputId": "ec8a44d6-98fb-4d22-b6b7-a964393ac356"
   },
   "outputs": [],
   "source": [
    "pd.Series(lrm.coef_, index = features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tLlqPIs6wTUD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ed0d1f81"
   },
   "source": [
    "- Model fit improves as we add more features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1714205f",
    "outputId": "78e6bc38-e5d5-4749-fa49-00d0d88dceec"
   },
   "outputs": [],
   "source": [
    "mean_squared_error(y, lrm.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ecb69dba"
   },
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>\n",
    "\n",
    "## Are we scoring our models correctly?\n",
    "\n",
    "So far, we have been computing MSE on the data used to train the model. This may lead to over-optimistic scores as the data has been already seen by the model when it was trained\n",
    "\n",
    "We need to understand our model's performance on new (previously unseen) data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "16e46ecf"
   },
   "source": [
    "##### To simulate \"new data\", we can split the original data set into two parts\n",
    "- Training set (50-90 %)\n",
    "- Test set (the remainder)\n",
    "    - random splitting works and is preferrable for most data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7a68c93d"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "b383651e",
    "outputId": "41e29444-f702-4d74-9a83-c702b7095d4b"
   },
   "outputs": [],
   "source": [
    "lrm = LinearRegression()\n",
    "lrm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2654d51b",
    "outputId": "69185810-f7dc-49fd-f1b8-5dc05050f323"
   },
   "outputs": [],
   "source": [
    "### training error\n",
    "\n",
    "mean_squared_error(y_train, lrm.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e0f8e8ee",
    "outputId": "bef0c37b-0534-4d64-ae7e-802f4ea4257e"
   },
   "outputs": [],
   "source": [
    "### test error\n",
    "\n",
    "mean_squared_error(y_test, lrm.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1c19eac1"
   },
   "source": [
    "### Discussion: which MSE is more important for model performance?\n",
    "\n",
    "- Train error\n",
    "    - OR\n",
    "- Test error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i1Gov2DYHQbm"
   },
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>\n",
    "\n",
    "## Learning as an Iterative Process\n",
    "\n",
    "__Generally, machine learning is approached as an optimization problem and is solved numerically using...__\n",
    "\n",
    "### Gradient Descent (SGD)\n",
    "\"S\" is for \"stochastic\"\n",
    "\n",
    "#### Definitions\n",
    "\n",
    "- Gradient descent (steepest descent) is an iterative optimization algorithm for finding a minimum of a function\n",
    "\n",
    "- In ML, gradient descent finds a set of model parameters (coefficients) to minimize a loss function such as MSE\n",
    "\n",
    "- Mathematically, to minimize means to find a \"valley\" where the first derivative of the loss function w.r.t. model coefficients `= 0`\n",
    "\n",
    "#### How does SGD work?\n",
    "\n",
    "\n",
    "<img src=\"./images/gradient_descent_01.gif\" alt=\"Bias and Variance\" height = \"600\" width=\"600\">\n",
    "\n",
    "<img src=\"./images/gradient_descent_02.gif\" alt=\"Bias and Variance\" width=\"900\">\n",
    "\n",
    "\n",
    "- Optional demo (homework): https://remykarem.github.io/backpropagation-demo/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "de959fc8"
   },
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>\n",
    "\n",
    "## Classification\n",
    "\n",
    "- Logistic Regression\n",
    "- K Nearest Neighbor (KNN)  Classifier\n",
    "- Random Forest Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a46e0ba3"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# import data preprocessing functions\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# import various metrics for model scoring\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "17dd9bbc"
   },
   "source": [
    "## Predict insurance claims\n",
    "\n",
    "Let's predict if a health insurance policy holder will make a major claim.\n",
    "- Import insurance2 dataset (originally from kaggle.com):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "66f3daf8",
    "outputId": "35c08d7f-efc1-4314-afd0-9f5eea2639d3"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/insurance2.csv\")\n",
    "df.head()\n",
    "## insuranceclaim is a categorical label >> Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "18bd5206",
    "outputId": "e71afed5-756c-4758-cd82-064a4593b059"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ba6329a1"
   },
   "source": [
    "- Feature engineering: perform necessary data transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "86d669e2",
    "outputId": "f01a5a13-aec2-4342-a8ec-ebdca4f53ef6"
   },
   "outputs": [],
   "source": [
    "### region is an integer but should be treated as a categorical variable one-hot encoded\n",
    "df['region'] = df['region'].astype('str')\n",
    "\n",
    "\n",
    "### use pd.get_dummies to encode all categorical variables (note they still can be \"str\" typed)\n",
    "df = pd.get_dummies(df, drop_first=True).astype('float')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f3c8cd8e",
    "outputId": "44ee268a-b323-4152-f6bd-4dbe7f7bebd9"
   },
   "outputs": [],
   "source": [
    "### create numpy arrays X and y\n",
    "label = 'insuranceclaim'\n",
    "features = list(df.columns)\n",
    "features.remove(label)\n",
    "X = df[features].to_numpy()\n",
    "y = df[label].to_numpy()\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7a3bb2c1"
   },
   "outputs": [],
   "source": [
    "## name label classes\n",
    "label_classes = ['Not_filed', 'Filed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ccc5e4f9"
   },
   "outputs": [],
   "source": [
    "### split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42)\n",
    "\n",
    "### perform min-max scaling using a sklearn function MinMaxScaler() - use fit and transform methods\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aab2158c"
   },
   "source": [
    "## Logistic Regression\n",
    "\n",
    "<img src=\"./images/logistic_regression.webp\" width=\"600\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "8bdad1b0",
    "outputId": "576d1b91-b464-4515-9f19-15e742304d38"
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HdRG-6fTzoof"
   },
   "source": [
    "## Scoring a Classifier:\n",
    "- MSE is a suitable score for numerical labels, but not for classes\n",
    "- Classifiers metrics are computed from the numbers of correctly vs incorrectly predicted classes\n",
    "\n",
    "<img src=\"./images/confusion_matrix.png\" width=\"700\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Isk_BT16BOU"
   },
   "outputs": [],
   "source": [
    "# Calculate the confusion matrix\n",
    "def classifier_scoring(model):\n",
    "\n",
    "  cm = confusion_matrix(y_test, model.predict(X_test))\n",
    "\n",
    "  print(f'Accuracy: {accuracy_score(y_test, model.predict(X_test)):.4f}')\n",
    "  print(f'Precision: {precision_score(y_test, model.predict(X_test)):.4f}')\n",
    "  print(f'Recall: {recall_score(y_test, model.predict(X_test)):.4f}')\n",
    "  print(f'F1 Score: {f1_score(y_test, model.predict(X_test)):.4f}')\n",
    "\n",
    "  # Plot the confusion matrix\n",
    "  plt.figure(figsize=(6, 4))\n",
    "  sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "                xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])\n",
    "  plt.xlabel('Predicted')\n",
    "  plt.ylabel('Actual')\n",
    "  plt.title('Confusion Matrix')\n",
    "  plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 479
    },
    "id": "vlvjSCv-8vU1",
    "outputId": "78509aa6-115d-4cac-a728-d20c6b8bead2"
   },
   "outputs": [],
   "source": [
    "classifier_scoring(lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e7eb4204"
   },
   "source": [
    "- Model interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0f41d75f",
    "outputId": "8cbf869c-cfd3-49bc-975c-27a630ddae76"
   },
   "outputs": [],
   "source": [
    "## model parameters (coefficients)\n",
    "##\n",
    "pd.Series(lr.coef_[0], index = features)\n",
    "## feature importance order: bmi, children, smoker, age, etc. ....."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e0bb40fd"
   },
   "source": [
    "#### Logistic Regression Summary\n",
    "\n",
    "- model type: generalized linear, parametric\n",
    "- model expression: sigmoid funcion of a linear mathematical expression evaluated w.r.t. a threshold\n",
    "- assumptions: classes are linearly separable\n",
    "- python implementation: sklearn.linear_model.LogisticRegression\n",
    "- hyperparameters: regularization parameters (we will discuss regularization later)\n",
    "- interpretability: high\n",
    "- scalability: high\n",
    "\n",
    "\n",
    "https://towardsdatascience.com/comparative-study-on-classic-machine-learning-algorithms-24f9ff6ab222"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "11d133f4"
   },
   "source": [
    "## K nearest neighbors (KNN)\n",
    "\n",
    "\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.metrics.DistanceMetric.html\n",
    "\n",
    "\n",
    "- To predict on new data X_new, find N nearest neighbours (using a distance metric such as \"euclidean\" or \"manhattan\") in the training data set. Vote on the majority class. Optionally, compute the probability (percentage of votes) for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "f84a9319",
    "outputId": "bd6bf740-4bbb-428b-a729-d49c763aba58"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()#n_neighbors = 18, metric = 'euclidean') #\n",
    "knn.fit(X_train, y_train)\n",
    "#print(classification_report(y_test, knn.predict(X_test), target_names = ['Not filed', 'Filed'])[:220])\n",
    "#print(\"confusion matrix:\\n\", confusion_matrix(y_test, knn.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 479
    },
    "id": "DuzPh5Oc61I_",
    "outputId": "0a9eb936-3dc4-4ce2-a24d-6f94cf968d6c"
   },
   "outputs": [],
   "source": [
    "# Calculate the confusion matrix\n",
    "\n",
    "classifier_scoring(knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fece6133"
   },
   "source": [
    "#### KNN and Overfit\n",
    "\n",
    "- What hyperparameters does KNN have?\n",
    "- What makes KNN overfit?\n",
    "\n",
    "\n",
    "    \n",
    "<img src=\"./images/KNN.png\" alt=\"KNN\" width=\"600\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8111d279"
   },
   "source": [
    "#### KNN Classifier Summary\n",
    "\n",
    "- model type: non-parametric\n",
    "- assumptions: none\n",
    "- python implementation: sklearn.neighbors.KNeighborsClassifier\n",
    "- hyperparameters: k (number of neighbours), distance type\n",
    "- interpretability: low\n",
    "- scalability: low (can be improved with \"non-brute\" distance algorithms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "efb5ffb8"
   },
   "source": [
    "## Random Forest Classifier\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BUyiOmdRA4tg"
   },
   "source": [
    "<img src=\"./images/border.jpg\" height=\"10\" width=\"1500\" align=\"center\"/>\n",
    "\n",
    "# **LAB:** Train a Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "77765df7",
    "outputId": "304b07d7-a3ac-4858-8b5a-c2d65c910592",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators=400)\n",
    "rfc.fit(X_train, y_train)\n",
    "print(classification_report(y_test, rfc.predict(X_test), target_names = ['Not filed', 'Filed'])[:220])\n",
    "pd.DataFrame(confusion_matrix(y_test, rfc.predict(X_test)))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
