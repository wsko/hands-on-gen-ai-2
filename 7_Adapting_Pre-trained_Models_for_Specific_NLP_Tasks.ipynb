{"cells":[{"cell_type":"markdown","metadata":{"id":"V2S7V0TPD9bo"},"source":["# **Adapting Pre-trained Models for Specific NLP Tasks**\n","\n","## **Outline**\n","\n","\n","- Transfer learning and full fine-tuning strategies for LLMs.\n","- Considerations for costs and potential catastrophic forgetfulness.\n","- Using Hugging Face's transformers library for fine-tuning\n","- Single task vs multi task fine tuning\n","- Retrieval-Augmented Generation (RAG)\n","- **Hands-on Lab:** Transfer learning and fine tuning\n"]},{"cell_type":"markdown","metadata":{"id":"yhVjU8GKD9bq"},"source":["<img src=\"https://github.com/wsko/Generative_AI/blob/main/Day-3/images/border.jpg?raw=1\" height=\"10\" width=\"1500\" align=\"center\"/>\n","\n","<hr style=\"border:2px solid blue\">"]},{"cell_type":"markdown","source":["# Transfer Learning and Fine Tuning\n","\n","- Transfer Learning focuses on reusing the pre-trained model as is, with minimal changes, while Fine-Tuning involves further training to tailor the model to the specific task.\n","- Transfer learning is typically used for simpler, more general tasks, whereas fine-tuning is preferred for more complex, specific tasks that benefit from additional training.\n","- Fine-tuning can potentially lead to better performance on the new task but requires more data and computational resources compared to transfer learning."],"metadata":{"id":"ZBGlr9qH0PKC"}},{"cell_type":"markdown","metadata":{"id":"tpqgKslAD9b6"},"source":["## **Pretrained vs. Fine-Tuned Models**\n","\n","- Pretraining\n","    - Pretraining uses a large corpus of data.\n","    - Training can take several weeks.\n","\n","---\n","\n","\n","![Embedding Classifier Example](https://github.com/wsko/Generative_AI/blob/main/Day-3/images/NLP7.svg?raw=1)\n","___\n","- Fine-Tuning\n","\n","  - Model Adaptation: Involves taking a pre-trained model and training it further on a new dataset, adjusting the weights of the entire model or a subset of layers to better fit the new task.\n","  - Task-Specific Customization: Allows for more customization and better performance on the new task since the model can learn more task-specific features by adjusting the existing weights.\n","  - Resource-Intensive: This process is more time-consuming and computationally demanding compared to transfer learning since it requires additional training on the new data.\n","___\n","\n","![Embedding Classifier Example](https://github.com/wsko/Generative_AI/blob/main/Day-3/images/NLP8.svg?raw=1)\n","___\n","- Why Not Just Pre-Train a Dedicated, Specialized Model?\n","  - Fine-tuning leverages knowledge from pretraining.\n","  - Requires less data, time, and resources."]},{"cell_type":"markdown","source":["***\n","## **Example Scenario: develop a generative AI app to write Patent Applications**\n","  - Pretrained model on large English text corpora (e.g., GPT-3).\n","  - Fine-tuning on millions of US Patents.\n","____"],"metadata":{"id":"6fLGghLfbUkd"}},{"cell_type":"markdown","source":["## Catastrophic Forgetfulness\n","\n","-  **Catastrophic Forgetfulness** occurs when a model forgets previously learned information upon learning new information. In the context of fine-tuning, this means the model might lose its ability to perform well on the original tasks it was pre-trained on after being fine-tuned on a specific task.\n","\n","- **Considerations:**\n","   - **Regularization Techniques:** Applying regularization methods such as Elastic Weight Consolidation (EWC) helps the model retain important weights related to previously learned tasks while learning new tasks.\n","   - **Sequential Fine-Tuning:** Gradually fine-tuning the model on multiple tasks sequentially, rather than all at once, can help mitigate catastrophic forgetting.\n","   - **Fine-Tuning Duration:** Monitoring the fine-tuning process and avoiding overfitting to the new task is crucial. Fine-tuning for too long on a specific task can lead to forgetting of previously learned information."],"metadata":{"id":"J3rF-nRcDH3d"}},{"cell_type":"markdown","source":["## Single-Task vs Multi-Task Fine-Tuning\n","\n","- **Single-Task Fine-Tuning:**\n","   - Fine-tunes a model on one specific task (e.g., sentiment analysis) using a dedicated dataset. Provides optimized performance for the targeted task as the model adapts specifically to its requirements.\n","   - **Limitations:** May not generalize well to other tasks and can lead to overfitting on the single task.\n","\n","- **Multi-Task Fine-Tuning:**\n","   - Fine-tunes a model on multiple tasks simultaneously (e.g., sentiment analysis, summarization, translation) using datasets for each task. Enhances the modelâ€™s ability to generalize across tasks by sharing knowledge and representations learned from different tasks.\n","   - **Limitations:** Can be complex to manage and balance task-specific requirements; risk of task interference where learning one task might negatively impact others.\n","\n","- **Task Interference and Synergy:**\n","   - **Single-Task:** Task-specific fine-tuning can lead to high performance but may forget previously learned tasks or have limited versatility.\n","   - **Multi-Task:** Task interference can occur, but it promotes a more versatile model by leveraging shared knowledge, which can improve overall performance and generalization across tasks."],"metadata":{"id":"AA-DSlhoD4wE"}},{"cell_type":"markdown","source":["### Retrieval-Augmented Generation (RAG) as an Alternative to Fine-Tuning\n","\n","- **RAG** combines retrieval and generation to enhance performance. The retrieval component fetches relevant information from a large corpus and a generation component to produce responses based on that information.\n","- The model first retrieves relevant documents from a pre-defined knowledge base using a retrieval mechanism (e.g., dense retrieval with embeddings), then, it generates responses by conditioning on the retrieved information\n"],"metadata":{"id":"xx8lDToUEYMz"}},{"cell_type":"markdown","source":["# Examples of fine-tuning BERT and GPT:\n","\n","#### Fine-Tuning BERT:\n","1. **Sentiment Analysis:**\n","   - Fine-tune BERT on a dataset like IMDb movie reviews to classify text as positive or negative.\n","   - The model adapts to understand sentiments specifically within the movie review context.\n","\n","2. **Question Answering:**\n","   - Use a dataset such as SQuAD (Stanford Question Answering Dataset) to fine-tune BERT.\n","   - The model learns to provide precise answers to questions based on a given context paragraph.\n","\n","3. **Named Entity Recognition (NER):**\n","   - Fine-tune BERT on a labeled dataset like CoNLL-2003 to identify and classify entities (e.g., names of people, organizations, locations) within text.\n","   - The model adjusts to recognize entities in the specific format and context of the new dataset.\n","\n","#### Fine-Tuning GPT:\n","1. **Text Summarization:**\n","   - Fine-tune GPT on a dataset of articles paired with their summaries, such as the CNN/Daily Mail dataset.\n","   - The model learns to generate concise summaries of long articles.\n","\n","2. **Chatbot Development:**\n","   - Use a conversational dataset like Persona-Chat to fine-tune GPT.\n","   - The model adapts to generate more human-like and contextually appropriate responses in a dialogue setting.\n","\n","3. **Code Generation:**\n","   - Fine-tune GPT on a dataset of code snippets and their descriptions or related comments, such as GitHub repositories.\n","   - The model learns to generate code based on textual descriptions or to complete code snippets.\n"],"metadata":{"id":"CuUWFsCZ2MBc"}},{"cell_type":"markdown","metadata":{"id":"dq2cSNwxD9b6"},"source":["<img src=\"https://github.com/wsko/Generative_AI/blob/main/Day-3/images/border.jpg?raw=1\" height=\"10\" width=\"1500\" align=\"center\"/>"]},{"cell_type":"markdown","metadata":{"id":"o4ck5Oz7D9b9"},"source":["## **Fine Tuning BERT for Text Classification**\n","\n","\n","\n","### **Step 1: Load Pre-trained BERT**\n","\n","- Import necessary libraries.\n","- Load pre-trained BERT tokenizer and model (e.g., `bert-base-uncased`).\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2041,"status":"ok","timestamp":1722481772863,"user":{"displayName":"Vlad Skorokhod","userId":"12641846192617263153"},"user_tz":240},"id":"GCRltLF-D9b-","outputId":"3944418e-fe0c-47a3-e58f-effd59170355"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["import torch\n","from transformers import BertTokenizer, BertForSequenceClassification\n","from torch.utils.data import DataLoader, TensorDataset\n","from sklearn.metrics import classification_report, accuracy_score\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# Load pre-trained BERT tokenizer and model\n","model_name = \"bert-base-uncased\"\n","tokenizer = BertTokenizer.from_pretrained(model_name)\n","model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2)  # 2 for binary classification\n"]},{"cell_type":"markdown","metadata":{"id":"JFopKtHRD9b-"},"source":["<img src=\"https://github.com/wsko/Generative_AI/blob/main/Day-3/images/border.jpg?raw=1\" height=\"10\" width=\"1500\" align=\"center\"/>"]},{"cell_type":"markdown","metadata":{"id":"MIIU_1EcD9b-"},"source":["\n","## **Step 2: Prepare Training Data**\n","\n","- Define sample training data and labels.\n","- Tokenize and encode the training data using the BERT tokenizer."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hRbI9lVDD9b-"},"outputs":[],"source":["# Sample training data\n","# texts = [\"This is a positive review.\", \"This is a negative review.\"]\n","# labels = [1, 0]  # 1 for positive, 0 for negative\n","\n","texts = [\"This movie is awful\", \"This is a negative review.\", \"Terrible movie, makes me rethink\", \"Entertaining film\"]\n","labels = [0, 0,0,1]  # 1 for positive, 0 for negative\n"]},{"cell_type":"code","source":[],"metadata":{"id":"BqACbtIv3Yyn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4pcLYp8OD9b-"},"source":["<img src=\"https://github.com/wsko/Generative_AI/blob/main/Day-3/images/border.jpg?raw=1\" height=\"10\" width=\"1500\" align=\"center\"/>"]},{"cell_type":"markdown","metadata":{"id":"he7JKsayD9b_"},"source":["## **Step 3: Create DataLoader**\n","\n","- Create a DataLoader for efficient training.\n","- Set batch size and shuffle the data."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7peNhEjbD9b_"},"outputs":[],"source":["\n","# Tokenize and encode the training data\n","input_ids = []\n","attention_masks = []\n","\n","for text in texts:\n","    encoded_text = tokenizer.encode_plus(\n","        text,\n","        add_special_tokens=True,\n","        max_length=128,\n","        pad_to_max_length=True,\n","        return_attention_mask=True,\n","        return_tensors=\"pt\"\n","    )\n","    input_ids.append(encoded_text['input_ids'])\n","    attention_masks.append(encoded_text['attention_mask'])\n","\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","labels = torch.tensor(labels)\n","\n","# Create a DataLoader for training data\n","batch_size = 2\n","train_dataset = TensorDataset(input_ids, attention_masks, labels)\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n"]},{"cell_type":"markdown","metadata":{"id":"t4ZhHNzlD9b_"},"source":["<img src=\"https://github.com/wsko/Generative_AI/blob/main/Day-3/images/border.jpg?raw=1\" height=\"10\" width=\"1500\" align=\"center\"/>"]},{"cell_type":"markdown","metadata":{"id":"6EPOJ0bDD9b_"},"source":["\n","## **Step 4: Fine-Tune BERT**\n","\n","- Set up optimization (e.g., AdamW) and training parameters.\n","- Iterate through epochs, compute loss, and update model weights."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T4psMoF0D9b_"},"outputs":[],"source":["\n","\n","# Fine-tuning BERT on the classification task (you can adjust the number of training epochs)\n","optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n","num_epochs = 3\n","\n","model.train()\n","for epoch in range(num_epochs):\n","    total_loss = 0\n","    for batch in train_loader:\n","        input_ids, attention_mask, label = batch\n","        optimizer.zero_grad()\n","        outputs = model(input_ids, attention_mask=attention_mask, labels=label)\n","        loss = outputs.loss\n","        total_loss += loss.item()\n","        loss.backward()\n","        optimizer.step()\n","    average_loss = total_loss / len(train_loader)\n","    print(f\"Epoch {epoch + 1}/{num_epochs}, Average Loss: {average_loss:.4f}\")\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"sTE9rb0YD9cA"},"source":["<img src=\"https://github.com/wsko/Generative_AI/blob/main/Day-3/images/border.jpg?raw=1\" height=\"10\" width=\"1500\" align=\"center\"/>"]},{"cell_type":"markdown","metadata":{"id":"Td1hX4-ND9cA"},"source":["\n","## **Step 5: Evaluation**\n","\n","- Switch to evaluation mode.\n","- Tokenize and encode sample test data.\n","- Make predictions and calculate classification metrics."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":741},"executionInfo":{"elapsed":1326,"status":"ok","timestamp":1722480396140,"user":{"displayName":"Vlad Skorokhod","userId":"12641846192617263153"},"user_tz":240},"id":"EINDuRw_D9cA","outputId":"90b8dfb9-d361-446d-ec24-2497a075e301"},"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted Labels: tensor([0, 0])\n","True Labels: [1 0]\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.50      1.00      0.67         1\n","           1       0.00      0.00      0.00         1\n","\n","    accuracy                           0.50         2\n","   macro avg       0.25      0.50      0.33         2\n","weighted avg       0.25      0.50      0.33         2\n","\n","Accuracy: 0.5\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 600x400 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["# Evaluation\n","model.eval()\n","test_texts = [\"This movie is great.\", \"I didn't like the film.\"]\n","true_labels = [1, 0]\n","\n","test_input_ids = []\n","test_attention_masks = []\n","\n","for text in test_texts:\n","    encoded_text = tokenizer.encode_plus(\n","        text,\n","        add_special_tokens=True,\n","        max_length=128,\n","        pad_to_max_length=True,\n","        return_attention_mask=True,\n","        return_tensors=\"pt\"\n","    )\n","    test_input_ids.append(encoded_text['input_ids'])\n","    test_attention_masks.append(encoded_text['attention_mask'])\n","\n","test_input_ids = torch.cat(test_input_ids, dim=0)\n","test_attention_masks = torch.cat(test_attention_masks, dim=0)\n","true_labels = torch.tensor(true_labels)\n","\n","with torch.no_grad():\n","    logits = model(test_input_ids, attention_mask=test_attention_masks).logits\n","\n","predicted_labels = np.argmax(logits, axis=1)\n","print(\"Predicted Labels:\", predicted_labels)\n","print(\"True Labels:\", true_labels.numpy())\n","\n","# Classification report and accuracy\n","classification_rep = classification_report(true_labels.numpy(), predicted_labels)\n","accuracy = accuracy_score(true_labels.numpy(), predicted_labels)\n","print(\"Classification Report:\\n\", classification_rep)\n","print(\"Accuracy:\", accuracy)\n","\n","# Visualization\n","fig, ax = plt.subplots(figsize=(6, 4))\n","labels = ['Negative', 'Positive']\n","y_pos = np.arange(len(labels))\n","scores = [logits[0][0].item(), logits[1][1].item()]\n","ax.bar(y_pos, scores, align='center', alpha=0.5)\n","ax.set_ylabel('Scores')\n","ax.set_xticks(y_pos)\n","ax.set_xticklabels(labels)\n","ax.set_title('BERT Sentiment Classification')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"K3VnUQsdD9cA"},"source":["<img src=\"https://github.com/wsko/Generative_AI/blob/main/Day-3/images/border.jpg?raw=1\" height=\"10\" width=\"1500\" align=\"center\"/>"]},{"cell_type":"markdown","metadata":{"id":"UCt2li0GD9cA"},"source":["## **OpenAI GPT Models**"]},{"cell_type":"markdown","metadata":{"id":"L7XAVr-ED9cE"},"source":["### **Using OpenAI's GPT with Hugging Face's Transformers**\n","\n","\n","**OpenAI's Generative Pretrained Transformer (GPT):**\n","- A state-of-the-art language model using Transformer architecture.\n","- Trained on vast amounts of text and can generate human-like text.\n","- Has multiple versions (e.g., GPT-2, GPT-3) with increasing model sizes and capabilities.\n","\n","**Hugging Face's Transformers:**\n","- A popular library for Natural Language Processing.\n","- Provides pre-trained models, including GPT variants.\n","- Facilitates easy fine-tuning, usage, and deployment of models.\n","\n","\n","- https://huggingface.co/docs/transformers/en/model_doc/gpt2\n","\n","-"]},{"cell_type":"markdown","metadata":{"id":"8meUUHiGD9cE"},"source":["<img src=\"https://github.com/wsko/Generative_AI/blob/main/Day-3/images/border.jpg?raw=1\" height=\"10\" width=\"1500\" align=\"center\"/>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6b5REghCD9cF"},"outputs":[],"source":["import torch\n","from transformers import GPT2Tokenizer, GPT2LMHeadModel\n"]},{"cell_type":"markdown","metadata":{"id":"05hvTGAoD9cF"},"source":["#### **Initializing the tokenizer and model**\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1xS1OeCJD9cF","outputId":"b8e9e794-12cc-47bc-f29b-45136a719ab7","colab":{"base_uri":"https://localhost:8080/","height":313,"referenced_widgets":["7af871f7c49d44b0a8c2b26d68762637","4ecdc7810c48467db42113b001712dca","6a81234c20324915a482e3d88091bf68","ed95ecc95ce3451eaf63dded274e83ee","5f8fc1e0d24241ffa41d785398f30bca","eae19e4a1c5d4668b05a465d82e55016","ece24d2cf6234833908a1ca8940e10bb","23e6e029b11b4ec1926a1f4f7b9cbde5","5238e63a8ed44baa9304644f0a83b3cd","855148a6d8ca432b9e09f3c06849b455","4922686b76404bd8ad449f2f44c1b993","73dc647769e74d86bb0eac219b5a75c6","d671e3ebd6d04727bb0717ce8018fd94","21ab845c7c5d4e4cbdcd0dd9f97c3de5","96dbb7e8e77545c9a1f94d330aa4aca9","451d8809604440c59fcf755a4a082c3c","5e4fab25cb864db7ba7f9bac0716f370","f2332f0149b84762839c1bb539cb4893","fce3e10a1a6c4c5682f2597d68af6b8e","9e573a648c2f479a83a37bf54003fe0d","b81444190bc44cc49920a6628e680514","eae1d856508c4412b137e95afea2ae15","0ec923ecf016410b8abc9175ef8e507a","05fd8329b9f4488c834202999059ef7a","483eadfe5e494d398f902db075d62f99","4f6c651597464c7b8f4500643b070107","d3b09952fd264e9aa4c4796ca4f38410","9b86cf3b20e64a6f922552a1b6e80236","c90d410f41c94d81a8e5189095100c19","61d1cda9dc76421298c01021481ab461","8deac36c83274f6d8158e4d8313dab48","17bc6ca085b54e55abc9d21cc74e90c4","7d60a3c3fe384683a94b145abda733c8","8e82676fe8ed41559ff7376b187e23ff","5b589bde007946a2bbbd3625f90bc7f7","c2d45abce6414ce794663556d3d6efac","33ed43b815554e1a958dc1fc60f4ac3d","9bf74bb626f442019230757554a3bd4b","cd01c10dc31c42d1b587ebd8786046fc","7b796c54f6194181815938832acb46c8","7fd9e1ee428c4181828056d7e3af51be","83482b1d39a7455ea995405cce6ee8ab","9cf9cf2176424962a0adbe60f1f4bba1","977c34ad3d0a4a32a06e82246fe8a28f","434f3246f76341e18df29917dfdb2410","94e2ad619d5245059e5da9c20f5cf87d","d117a750abcb4cdd9525f7dd8891d30d","157d99bea2c346a894d814440d355776","a202f531b244411c9c0df95f4e8b9593","a5cb29eb34bb47d9b01c29f47e3e8486","d06517d0eee94f52b9fc2e8aeed58dc9","cc24d49598ca451681513c54795eaa50","70cabcc11af246978d1ee21a2c5958b9","52f60a49db49466d90a83c46020d213a","7f1dcc6619b9448bbc87b5d008c094d5","c343ceef05cb43539c20b363ff0d9d73","1e99ad7fbfa941898b9582683007ab06","cb793342c2bd497395fcdef4621b7fcc","48c7f62937e84e5aa4fdc812ee306ce2","1cf7165926824ceeb08d355a96d98928","62a50eb0dc2e453fa9a95c3af631b9f8","efa41ce24629401fa82050e8a607e351","a70c81d2099f4cab92ede3d3e1ba944f","5174f25009164d03931f2cb550067bc1","c683ee2ab8b346d9bbb3c2f7097ff25a","2963d05c06b24bcdb72340620a0e3f8b","a9d513e934ea4f10b18564e446969046","a62059057a124a4fb0e763c2dd9b703c","99a2aae44018485ba391789872dd1fb5","c71446b9c3334a07a3ee7aae0142b758","ffc40ebe1aec4b18b43d568fffed6b85","6fbbef1cc5c44058b508c21d1021cd9e","eb18219a9d154d81899cdf79863a49a8","eea553aac6b7454b952b1b71c9e58a2f","b54149bee0fc4d81b06e70b93ab1241e","f004b8065d124e05af207da8f578dcfb","5cb9d9b1d55e496b8642b39c2da47d43"]},"executionInfo":{"status":"ok","timestamp":1720581619499,"user_tz":240,"elapsed":20774,"user":{"displayName":"Vlad Skorokhod","userId":"12641846192617263153"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7af871f7c49d44b0a8c2b26d68762637"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73dc647769e74d86bb0eac219b5a75c6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ec923ecf016410b8abc9175ef8e507a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e82676fe8ed41559ff7376b187e23ff"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/718 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"434f3246f76341e18df29917dfdb2410"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/1.52G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c343ceef05cb43539c20b363ff0d9d73"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9d513e934ea4f10b18564e446969046"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["cpu\n"]}],"source":["# Load pre-trained GPT-2 tokenizer\n","tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2-medium\")\n","\n","# Load the pre-trained GPT-2 model\n","model = GPT2LMHeadModel.from_pretrained(\"gpt2-medium\")\n","\n","# Ensure the model is in eval mode (important for models with dropout or batchnorm)\n","model.eval()\n","\n","# If you have a GPU available, move the model there\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","# device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n","model.to(device)\n","print(device)"]},{"cell_type":"markdown","metadata":{"id":"F4k-SSq1D9cG"},"source":["<img src=\"https://github.com/wsko/Generative_AI/blob/main/Day-3/images/border.jpg?raw=1\" height=\"10\" width=\"1500\" align=\"center\"/>"]},{"cell_type":"markdown","metadata":{"id":"UXY3x-HSD9cG"},"source":["#### **Generate text given a prompt**\n","\n","To generate text with GPT-2:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wiB3cteGD9cG","outputId":"fb1ab8f6-43ed-4d23-a53e-3276dad6c13c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720581654080,"user_tz":240,"elapsed":34597,"user":{"displayName":"Vlad Skorokhod","userId":"12641846192617263153"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["Once upon a time, there was a man who lived in a village called Krakow. He was a very good man, and he was very kind to his children. One day, he was walking along the road, and he saw a woman walking by. He asked her if she was his daughter. She said yes, and she said that she was his daughter. He asked her if she was his wife. She said yes, and she said that she was his wife. He asked her\n"]}],"source":["def generate_text(prompt, max_length=100, temperature=1.0):\n","    # Encode the prompt text to tensor\n","    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n","\n","    # Generate text using the model\n","    with torch.no_grad():\n","        generated_ids = model.generate(input_ids=input_ids, max_length=max_length, num_return_sequences=1, temperature=temperature)[0]\n","\n","    # Decode the tensor to a text string\n","    generated_text = tokenizer.decode(generated_ids, skip_special_tokens=True)\n","    return generated_text\n","\n","# Try it out!\n","prompt = \"Once upon a time\"\n","print(generate_text(prompt))"]},{"cell_type":"markdown","metadata":{"id":"_cnj3aeAD9cG"},"source":["<img src=\"https://github.com/wsko/Generative_AI/blob/main/Day-3/images/border.jpg?raw=1\" height=\"10\" width=\"1500\" align=\"center\"/>"]},{"cell_type":"markdown","metadata":{"id":"XaSUSUYpD9cH"},"source":["\n","#### **Adjusting generation parameters**\n","\n","The `generate()` method provides a lot of parameters to play with to customize the generation process:\n","\n","- `max_length`: Maximum length of the generated text.\n","- `temperature`: Controls randomness. Higher values (e.g., 1.0) make generation more random, while lower values (e.g., 0.7) make it more deterministic.\n","- `num_return_sequences`: Number of independently computed returned sequences. If you want multiple variations of generated text, increase this number.\n","- ... and many more (refer to the Hugging Face documentation for a detailed list).\n"]},{"cell_type":"markdown","metadata":{"id":"hoRAdVRVD9cH"},"source":["<img src=\"https://github.com/wsko/Generative_AI/blob/main/Day-3/images/border.jpg?raw=1\" height=\"10\" width=\"1500\" align=\"center\"/>"]},{"cell_type":"markdown","metadata":{"id":"35IYPzZND9cH"},"source":["#### **6. Using other GPT versions**\n","\n","Hugging Face's library supports multiple versions of GPT models like `gpt2`, `gpt2-medium`, `gpt2-large`, and `gpt2-xl`. Simply replace the model name in the `from_pretrained()` function to switch between them.\n"]},{"cell_type":"markdown","metadata":{"id":"OiI_hEOqg5rW"},"source":["<img src=\"https://github.com/wsko/Generative_AI/blob/main/Day-3/images/border.jpg?raw=1\" height=\"10\" width=\"1500\" align=\"center\"/>\n","\n","## **Example: Question Answering with GPT-2**\n","\n","- **Exerecise:** replace the training phrase and questions with your own examples"]},{"cell_type":"code","source":["import torch\n","from transformers import GPT2Tokenizer, GPT2ForQuestionAnswering\n","\n","# Initialize the tokenizer and model\n","tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n","model = GPT2ForQuestionAnswering.from_pretrained('gpt2')\n","\n","# Add a padding token to the tokenizer\n","tokenizer.pad_token = tokenizer.eos_token\n","\n","# Example context and question\n","context = \"Huggingface's Transformers library provides thousands of pretrained models to perform tasks on different modalities such as text, vision, and audio.\"\n","question = \"What does Huggingface's Transformers library provide?\"\n","\n","# Encode the input\n","inputs = tokenizer(question, context, return_tensors='pt', truncation=True, padding=True)\n","\n","# Get model outputs\n","with torch.no_grad():\n","    outputs = model(**inputs)\n","\n","# Extract the answer (start and end logits)\n","start_logits = outputs.start_logits\n","end_logits = outputs.end_logits\n","\n","# Find the start and end positions with the highest scores\n","start_idx = torch.argmax(start_logits)\n","end_idx = torch.argmax(end_logits)\n","\n","# Decode the answer\n","input_ids = inputs['input_ids'][0]\n","answer = tokenizer.decode(input_ids[start_idx:end_idx+1])\n","\n","print(f\"Question: {question}\")\n","print(f\"Answer: {answer}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iR0UnUH6gw3Y","executionInfo":{"status":"ok","timestamp":1722525935785,"user_tz":240,"elapsed":4161,"user":{"displayName":"Vlad Skorokhod","userId":"12641846192617263153"}},"outputId":"33c1a04c-19d1-4c52-f457-e2ac8ceef872"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of GPT2ForQuestionAnswering were not initialized from the model checkpoint at gpt2 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Question: What does Huggingface's Transformers library provide?\n","Answer:  does Huggingface's Transformers library provide?Huggingface's Transformers library provides thousands of pretrained models to\n"]}]},{"cell_type":"markdown","metadata":{"id":"t80PwH6pD9cH"},"source":["<img src=\"https://github.com/wsko/Generative_AI/blob/main/Day-3/images/border.jpg?raw=1\" height=\"10\" width=\"1500\" align=\"center\"/>"]},{"cell_type":"markdown","source":["# **Lab:** Fine-Tuning BERT for the Finance Sentiment Dataset\n","\n","- Modify the demo example to perform training on the Finance Sentiment data: https://github.com/wsko/Statistics/raw/main/finance_sentiment.csv\n","\n","- Adjust batch size, number of epochs and other hyperparameters\n","\n","- Be mindful of Colab resource limitation: start with a small subset of the training data (10-20 examples)\n"],"metadata":{"id":"-NASMQDV-o5Z"}},{"cell_type":"code","source":[],"metadata":{"id":"y6eFPYIUjiRu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"K9OUkGhdB6-m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","from transformers import BertTokenizer, BertForSequenceClassification\n","from torch.utils.data import DataLoader, TensorDataset\n","from sklearn.metrics import classification_report, accuracy_score\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# Load pre-trained BERT tokenizer and model\n","model_name = \"bert-base-uncased\"\n","tokenizer = BertTokenizer.from_pretrained(model_name)\n","model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2)  # 2 for binary classification\n"],"metadata":{"id":"h55rhKiGB7D8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","df = pd.read_csv(\"https://github.com/wsko/Statistics/raw/main/finance_sentiment.csv\", encoding='latin-1')\n","\n","\n","texts = list(df['text'].values)[:1000]\n","labels = list(df['label'].values)[:1000]\n","\n","for i in range(10):\n","  print(texts[i], '\\n', labels[i])\n"],"metadata":{"id":"3lkvMDlxB71S","executionInfo":{"status":"ok","timestamp":1722524961769,"user_tz":240,"elapsed":1158,"user":{"displayName":"Vlad Skorokhod","userId":"12641846192617263153"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"fadc648b-ebc9-4e7c-9472-c163cabdd569"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Its market share widened to 48.51 percent from 48.31 percent a year earlier . \n"," 1\n","In Q1 of 2009 , the company 's result before taxes from continuing operations , excluding non-recurring items , totalled EUR -0.4 mn , compared to EUR -0.1 mn in the corresponding period in 2008 . \n"," 0\n","The pretax profit of the group 's life insurance business increased to EUR 36 million from EUR 27 million . \n"," 1\n","Finnish airline Finnair is starting the temporary layoffs of cabin crews in February 2010 . \n"," 0\n","Stora Enso Oyj said its second-quarter result would fall by half compared with the same period in 2007 . \n"," 0\n","Changes in the market situation and tougher price competition have substantially reduced demand for bread packaging manufactured at the Kauhava plant , according to the company . \n"," 0\n","The dismissed staff members will now take the matter to court unless it can be settled outside . \n"," 0\n","Viking Line head Jan Kaarstroem told TT that his company 's ferries were well equipped to handle ice and that all the passengers were safe . \n"," 1\n","The operating margin came down to 2.4 % from 5.7 % . \n"," 0\n","Aspocomp has repaid its interest bearing liability to Standard Chartered Bank and will use the rest of the consideration to partially repay its interest bearing liabilities in Finland and to improve its liquidity . \n"," 1\n"]}]},{"cell_type":"code","source":["\n","# Tokenize and encode the training data\n","input_ids = []\n","attention_masks = []\n","\n","for text in texts:\n","    encoded_text = tokenizer.encode_plus(\n","        text,\n","        add_special_tokens=True,\n","        max_length=128,\n","        pad_to_max_length=True,\n","        return_attention_mask=True,\n","        return_tensors=\"pt\"\n","    )\n","    input_ids.append(encoded_text['input_ids'])\n","    attention_masks.append(encoded_text['attention_mask'])\n","\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","labels = torch.tensor(labels)\n","\n","# Create a DataLoader for training data\n","batch_size = 10\n","train_dataset = TensorDataset(input_ids, attention_masks, labels)\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n"],"metadata":{"id":"khjCvLyhCGQb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Fine-tuning BERT on the classification task (you can adjust the number of training epochs)\n","optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n","num_epochs = 3\n","\n","model.train()\n","for epoch in range(num_epochs):\n","    total_loss = 0\n","    for batch in train_loader:\n","        input_ids, attention_mask, label = batch\n","        optimizer.zero_grad()\n","        outputs = model(input_ids, attention_mask=attention_mask, labels=label)\n","        loss = outputs.loss\n","        total_loss += loss.item()\n","        loss.backward()\n","        optimizer.step()\n","    average_loss = total_loss / len(train_loader)\n","    print(f\"Epoch {epoch + 1}/{num_epochs}, Average Loss: {average_loss:.4f}\")\n","\n","\n"],"metadata":{"id":"qNKlIUAcCdnT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Evaluation\n","model.eval()\n","test_texts = list(df['text'].values)[1001:1050]\n","true_labels = list(df['label'].values)[1001:1050]\n","\n","\n","test_input_ids = []\n","test_attention_masks = []\n","\n","for text in test_texts:\n","    encoded_text = tokenizer.encode_plus(\n","        text,\n","        add_special_tokens=True,\n","        max_length=128,\n","        pad_to_max_length=True,\n","        return_attention_mask=True,\n","        return_tensors=\"pt\"\n","    )\n","    test_input_ids.append(encoded_text['input_ids'])\n","    test_attention_masks.append(encoded_text['attention_mask'])\n","\n","test_input_ids = torch.cat(test_input_ids, dim=0)\n","test_attention_masks = torch.cat(test_attention_masks, dim=0)\n","true_labels = torch.tensor(true_labels)\n","\n","with torch.no_grad():\n","    logits = model(test_input_ids, attention_mask=test_attention_masks).logits\n","\n","predicted_labels = np.argmax(logits, axis=1)\n","print(\"Predicted Labels:\", predicted_labels)\n","print(\"True Labels:\", true_labels.numpy())\n","\n","# Classification report and accuracy\n","classification_rep = classification_report(true_labels.numpy(), predicted_labels)\n","accuracy = accuracy_score(true_labels.numpy(), predicted_labels)\n","print(\"Classification Report:\\n\", classification_rep)\n","print(\"Accuracy:\", accuracy)\n","\n","# Visualization\n","fig, ax = plt.subplots(figsize=(6, 4))\n","labels = ['Negative', 'Positive']\n","y_pos = np.arange(len(labels))\n","scores = [logits[0][0].item(), logits[1][1].item()]\n","ax.bar(y_pos, scores, align='center', alpha=0.5)\n","ax.set_ylabel('Scores')\n","ax.set_xticks(y_pos)\n","ax.set_xticklabels(labels)\n","ax.set_title('BERT Sentiment Classification')\n","plt.show()"],"metadata":{"id":"j8Hjvgy-Cljt"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1Pks-nQPBaXQ8JMCt_3C1v3iYsUrK1msK","timestamp":1721838000721},{"file_id":"1ee6xPfKXuRn5mfipM3-_pWdxVw_JMF00","timestamp":1721837913069},{"file_id":"https://github.com/wsko/Generative_AI/blob/main/Day-3/Part-1.ipynb","timestamp":1716947795355}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"}},"nbformat":4,"nbformat_minor":0}